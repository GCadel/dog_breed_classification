{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DoggieTech Dog Image Classifier - Data Import and Cleaning\n",
    "A machine learning model to identify a dog breed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\tap\\anaconda3\\lib\\site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\tap\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\tap\\anaconda3\\lib\\site-packages (from kaggle) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\tap\\anaconda3\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in c:\\users\\tap\\anaconda3\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tap\\anaconda3\\lib\\site-packages (from kaggle) (4.66.5)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\tap\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\tap\\anaconda3\\lib\\site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: bleach in c:\\users\\tap\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tap\\anaconda3\\lib\\site-packages (from bleach->kaggle) (24.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\tap\\anaconda3\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\tap\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tap\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tap\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\tap\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Dataset URL: https://www.kaggle.com/datasets/jessicali9530/stanford-dogs-dataset\n",
      "License(s): other\n",
      "stanford-dogs-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "# Get dataset from Kaggle\n",
    "!pip install kaggle\n",
    "!kaggle datasets download -d jessicali9530/stanford-dogs-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip dataset for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"stanford-dogs-dataset.zip\", \"r\") as z:\n",
    "  z.extractall(\"sd_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image formatting helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 100\n",
    "MAX_CATEGORY_SIZE = 3\n",
    "# Reduced category output due to limited data\n",
    "reducedListLabels = ('rottweiler', 'border_collie', 'golden_retriever')\n",
    "\n",
    "def convertImgToNpArray(anImage: Image):\n",
    "  return np.array(anImage)\n",
    "\n",
    "def cropImage(anImage, boundingBox: tuple):\n",
    "  return anImage.crop(boundingBox)\n",
    "\n",
    "def resizeImage(anImage: Image, aSize: int):\n",
    "  return anImage.resize((aSize, aSize))\n",
    "\n",
    "def to24Bit(anImage: Image):\n",
    "  return anImage.convert('L')\n",
    "\n",
    "def displayImage(anImageArray: np.array):\n",
    "  plt.imshow(anImageArray)\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dataframe to link attributes to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotationParse(annotationDir : str, imageDir : str):\n",
    "  annotationDict = [['id', 'breed','image location','xStart', 'yStart', 'xEnd', 'yEnd']]\n",
    "\n",
    "  # For every cateogory (aka dog breed)\n",
    "  # for breedDir in os.listdir(annotationDir):\n",
    "  \n",
    "  # for breedDir in os.listdir(annotationDir)[:MAX_CATEGORY_SIZE]:\n",
    "  for breedDir in os.listdir(annotationDir):\n",
    "    # For every dog\n",
    "    if breedDir.lower().endswith(reducedListLabels):\n",
    "      # print(breedDir)\n",
    "      for sampleDog in os.listdir(os.path.join(annotationDir, breedDir)):\n",
    "        # Generate XML root\n",
    "        tree = ET.parse(os.path.join(annotationDir, breedDir, sampleDog))  \n",
    "        root = tree.getroot()\n",
    "        # Set dog image\n",
    "        dogImg = os.path.join(imageDir, breedDir, sampleDog + \".jpg\")\n",
    "        # Get dog breed\n",
    "        dogBreed = root[5][0].text\n",
    "        # Get dog ID / file name (annotation file name)\n",
    "        dogID = sampleDog\n",
    "        # Get image bounding box\n",
    "        xStart, yStart, xEnd, yEnd = (\n",
    "          root[5][4][0].text,\n",
    "          root[5][4][1].text,\n",
    "          root[5][4][2].text,\n",
    "          root[5][4][3].text\n",
    "          )\n",
    "        # Add dog info to dictionary\n",
    "        annotationDict.append([dogID, dogBreed, dogImg, xStart, yStart, xEnd, yEnd])\n",
    "\n",
    "  annotationDict = np.array(annotationDict)\n",
    "  return pd.DataFrame(annotationDict[1:], columns=annotationDict[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing the images into a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotationDir = os.path.join(\"sd_dataset\",\"annotations\",\"Annotation\")\n",
    "imageDir = os.path.join(\"sd_dataset\",\"images\",\"Images\")\n",
    "\n",
    "dataFrame=annotationParse(annotationDir=annotationDir, imageDir=imageDir)\n",
    "dataFrame.to_pickle(\"./DogBreedData.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating lists for labels and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a DataFrame and generate labels and data for training\n",
    "def createLabelAndDataLists(dataFrame: pd.DataFrame):\n",
    "  data = []\n",
    "  labels = []\n",
    "  for item in dataFrame.itertuples():\n",
    "    # Format the image, transform into np array\n",
    "    boundingBox = (int(item[4]), int(item[5]), int(item[6]), int(item[7]))\n",
    "    image = Image.open(item[3], 'r')\n",
    "    # formattedImage = convertImgToNpArray(resizeImage(cropImage(anImage=image, boundingBox=boundingBox), 250))\n",
    "    formattedImage = to24Bit(resizeImage(cropImage(anImage=image, boundingBox=boundingBox), IMG_SIZE))\n",
    "    image.close()\n",
    "\n",
    "    # Add the corresponding image and label to appropriate list\n",
    "    data.append(formattedImage)\n",
    "    labels.append(item[2])\n",
    "  return data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data and labels\n",
    "data, labels = createLabelAndDataLists(dataFrame=dataFrame)\n",
    "\n",
    "def showSamples():\n",
    "  for i in range(0,len(data), 1000):\n",
    "    plt.figure()\n",
    "    plt.text(0,0,labels[i])\n",
    "    plt.imshow(data[i])\n",
    "# showSamples()\n",
    "\n",
    "# Final transformation of data for reading\n",
    "dataCopy = []\n",
    "for i in range(len(data)):\n",
    "  item = np.array(data[i]).flatten()\n",
    "  dataCopy.append(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./inputs_and_labels.pickle\", 'wb') as f:\n",
    "  pickle.dump({'data': dataCopy, 'labels':labels}, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
